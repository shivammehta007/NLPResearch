{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentence = 'Hello Shivam Mehta! How are you? How is it going? everything is alright lets learn something new? I am fine thank you. It was pleasure to meet you.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: ['Hello Shivam Mehta!', 'How are you?', 'How is it going?', 'everything is alright lets learn something new?', 'I am fine thank you.', 'It was pleasure to meet you.']\n",
      "words : ['Hello', 'Shivam', 'Mehta', '!', 'How', 'are', 'you', '?', 'How', 'is', 'it', 'going', '?', 'everything', 'is', 'alright', 'lets', 'learn', 'something', 'new', '?', 'I', 'am', 'fine', 'thank', 'you', '.', 'It', 'was', 'pleasure', 'to', 'meet', 'you', '.']\n"
     ]
    }
   ],
   "source": [
    "print('sentence: {}'.format(sent_tokenize(example_sentence)))\n",
    "print('words : {}'.format(word_tokenize(example_sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'shivam', 'mehta', '!', '?', 'going', '?', 'everything', 'alright', 'lets', 'learn', 'something', 'new', '?', 'fine', 'thank', '.', 'pleasure', 'meet', '.']\n"
     ]
    }
   ],
   "source": [
    "english_stop_words = set(stopwords.words('english'))\n",
    "filtered_words = list(filter(lambda x: x not in english_stop_words, word_tokenize(example_sentence.lower())))\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'python', 'python', 'python', 'pythonli']\n"
     ]
    }
   ],
   "source": [
    "stemming_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\" ]\n",
    "print(list(map(ps.stem, stemming_words )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming the example text we considering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'shivam', 'mehta', '!', '?', 'go', '?', 'everyth', 'alright', 'let', 'learn', 'someth', 'new', '?', 'fine', 'thank', '.', 'pleasur', 'meet', '.']\n"
     ]
    }
   ],
   "source": [
    "print(list(map(ps.stem,filtered_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging ( POS Tagging)\n",
    "\n",
    "POS tag list:\n",
    "\n",
    "CC\tcoordinating conjunction  \n",
    "CD\tcardinal digit  \n",
    "DT\tdeterminer  \n",
    "EX\texistential there (like: \"there is\" ... think of it like \"there exists\")  \n",
    "FW\tforeign word  \n",
    "IN\tpreposition/subordinating conjunction  \n",
    "JJ\tadjective\t'big'  \n",
    "JJR\tadjective, comparative\t'bigger'   \n",
    "JJS\tadjective, superlative\t'biggest'  \n",
    "LS\tlist marker\t1)  \n",
    "MD\tmodal\tcould, will  \n",
    "NN\tnoun, singular 'desk'  \n",
    "NNS\tnoun plural\t'desks'  \n",
    "NNP\tproper noun, singular\t'Harrison'  \n",
    "NNPS\tproper noun, plural\t'Americans'  \n",
    "PDT\tpredeterminer\t'all the kids'  \n",
    "POS\tpossessive ending\tparent\\'s  \n",
    "PRP\tpersonal pronoun\tI, he, she  \n",
    "PRP\\\\$\tpossessive pronoun\tmy, his, hers  \n",
    "RB\tadverb\tvery, silently,  \n",
    "RBR\tadverb, comparative\tbetter  \n",
    "RBS\tadverb, superlative\tbest  \n",
    "RP\tparticle\tgive up  \n",
    "TO\tto\tgo 'to' the store.  \n",
    "UH\tinterjection\terrrrrrrrm  \n",
    "VB\tverb, base form\ttake  \n",
    "VBD\tverb, past tense\ttook  \n",
    "VBG\tverb, gerund/present participle\ttaking  \n",
    "VBN\tverb, past participle\ttaken  \n",
    "VBP\tverb, sing. present, non-3d\ttake  \n",
    "VBZ\tverb, 3rd person sing. present\ttakes  \n",
    "WDT\twh-determiner\twhich  \n",
    "WP\twh-pronoun\twho, what  \n",
    "WP\\\\$\tpossessive wh-pronoun\twhose  \n",
    "WRB\twh-abverb\twhere, when  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.corpus import state_union\n",
    "train_text = state_union.raw('2005-GWBush.txt')\n",
    "sentence_tokenizer = PunktSentenceTokenizer(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Shivam Mehta!', 'How are you?', 'How is it going?', 'everything is alright lets learn something new?', 'I am fine thank you.', 'It was pleasure to meet you.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentence = sentence_tokenizer.tokenize(example_sentence)\n",
    "print(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Hello', 'NNP'), ('Shivam', 'NNP'), ('Mehta', 'NNP'), ('!', '.')], [('How', 'WRB'), ('are', 'VBP'), ('you', 'PRP'), ('?', '.')], [('How', 'WRB'), ('is', 'VBZ'), ('it', 'PRP'), ('going', 'VBG'), ('?', '.')], [('everything', 'NN'), ('is', 'VBZ'), ('alright', 'JJ'), ('lets', 'NNS'), ('learn', 'VBP'), ('something', 'NN'), ('new', 'JJ'), ('?', '.')], [('I', 'PRP'), ('am', 'VBP'), ('fine', 'JJ'), ('thank', 'NN'), ('you', 'PRP'), ('.', '.')], [('It', 'PRP'), ('was', 'VBD'), ('pleasure', 'NN'), ('to', 'TO'), ('meet', 'VB'), ('you', 'PRP'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print(list(map(nltk.pos_tag, [word_tokenize(sentence) for sentence in tokenized_sentence])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
