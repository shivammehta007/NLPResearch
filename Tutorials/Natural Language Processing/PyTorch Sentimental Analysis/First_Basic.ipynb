{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First_Basic.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivammehta007/NLPResearch/blob/master/Tutorials/Natural%20Language%20Processing/PyTorch%20Sentimental%20Analysis/First_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60yYrUe04rn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "from torchtext import data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLU7GJku4roA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3980372f-1a44-4e38-b63a-ec4a3ce40f27"
      },
      "source": [
        "SEED = 1234\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f63330f29b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4MUItRv4roL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field(tokenize = 'spacy')\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V43KzXAZ4roN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4dbc8f72-29e2-4bef-8e38-c16d68cbdb76"
      },
      "source": [
        "from torchtext import datasets\n",
        "train_dataset , test_dataset = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:08<00:00, 10.5MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaEKwziK4roQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a66ca12-cb25-46c1-aaf9-746faa4619f7"
      },
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iytNz3I9xM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, validation_data = train_dataset.split(random_state= random.seed(SEED))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKOalK7K-MDJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4560db7f-8d19-45f0-b826-127cedaf8f94"
      },
      "source": [
        "len(train_data), len(validation_data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17500, 7500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM_xMWhd_UGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcdKbsfJ_s_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "96dfcd2d-46e4-41e3-aec5-df1443441870"
      },
      "source": [
        "print(len(TEXT.vocab), len(LABEL.vocab))\n",
        "print(TEXT.vocab.freqs.most_common(20))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25002 2\n",
            "[('the', 202273), (',', 191724), ('.', 165509), ('and', 109826), ('a', 109039), ('of', 100566), ('to', 93435), ('is', 76237), ('in', 61513), ('I', 53946), ('it', 53635), ('that', 49166), ('\"', 44415), (\"'s\", 42942), ('this', 42362), ('-', 37016), ('/><br', 35354), ('was', 35200), ('as', 30258), ('with', 29916)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw0CGHpomElr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1adeeb50-b181-4c9c-906c-7653ffe0ea1c"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIKeLKta_wvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZES= 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xt4FKy3AwNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits( (train_data, validation_data, test_dataset ), batch_size=BATCH_SIZES, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3-cnTfUBbeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dims, embedded_dim, hidden_dim, output_dim):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dims, embedded_dim)\n",
        "        self.rnn = nn.RNN(embedded_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        return self.fc(hidden.squeeze(0))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LOdHJrEC2IU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnHVaSGRExLw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "732972ba-0418-4aa4-9f21-e09fc9e12b15"
      },
      "source": [
        "print('Number Of Trainable Parameters: {:,}'.format(sum(p.numel() for p in model.parameters())))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Of Trainable Parameters: 2,592,105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNIJosmGklDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimzer = optim.SGD(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoXrPeqzleIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nn.BCEWithLogitsLoss()\n",
        "model = model.to(device)\n",
        "loss = loss.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ1dIeg6l5QS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_accuracy(y_pred, y):\n",
        "    rounded_pred = torch.round(torch.sigmoid(y_pred))\n",
        "    correct = (rounded_pred == y).float()\n",
        "    accuracy = correct.sum()/ len(y_pred)\n",
        "    return accuracy\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBrkzDxsmxNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, loss_function):\n",
        "    epoch_accuracy = 0\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        prediction = model(batch.text).squeeze(1)\n",
        "        loss = loss_function(prediction, batch.label)\n",
        "        accuracy = binary_accuracy(prediction, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_accuracy += accuracy.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator) , epoch_acc / len(iterator)\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbKkt0q2qVMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U8nsnvSq5hH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, loss_function):\n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            prediction = model(batch.text)\n",
        "            loss = loss_function(predcition, batch.label)\n",
        "            acc = binary_accuracy(prediction, batch.label)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            epoch_accuracy += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator) , epoch_accuracy/ len(iterator)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLuMZaVrxajA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in EPOCHS:\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_accuracy = train(model, train_iterator, optimizer, loss)\n",
        "    valid_loss, valid_accurayc = evaluate(model, valid_iterator, loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_sec = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "        \n",
        "    print('Epoch : {:2}, Epoch Time : {:2}m{:2}s'.format(epoch, epoch_mins, epoch_sec))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}