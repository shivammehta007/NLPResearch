{"cells":[{"metadata":{"_uuid":"48687ed97124814c0206bae31b9d975b9fbfdcdd"},"cell_type":"markdown","source":"# DCGAN with CelebA"},{"metadata":{"_uuid":"6d166cbcdba9c22c4fefcca35ac97974e4475143"},"cell_type":"markdown","source":"## 1. Data"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-03T09:29:58.235472Z","start_time":"2018-04-03T09:22:25.522388Z"},"_uuid":"6c8ebb69f739967bef74a54fa950f9d56df48e1e"},"cell_type":"markdown","source":"```script\nchmod +x download.sh\n./download.sh\nunzip -q CelebA_128crop_FD.zip?dl=0 -d ./data/\n```"},{"metadata":{"_uuid":"2cfb27e74699e539b237df2f4018986223ed9259"},"cell_type":"markdown","source":"## 2. Import Libs"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T06:02:48.295105Z","start_time":"2018-04-04T06:02:47.939168Z"},"trusted":true,"_uuid":"168f7a50c59881d213fc8944aba4daf5a80e5709"},"cell_type":"code","source":"from __future__ import print_function\nimport torch\nimport os\nimport random\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data as tutils\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 1234\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\nnp.random.seed(SEED)\ntorch.backends.cudnn.deterministic = True\nrandom.seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d97055aa17f160648e6840a20590fd2256249083"},"cell_type":"markdown","source":"## 3. Hyperparameters"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T06:02:48.953705Z","start_time":"2018-04-04T06:02:48.930677Z"},"trusted":true,"_uuid":"20e09172b51911239d77a70c43618033d1b52224"},"cell_type":"code","source":"IMAGE_PATH = '../input/celeba-dataset/img_align_celeba/'\nSAMPLE_PATH = '../'\n\nif not os.path.exists(SAMPLE_PATH):\n    os.makedirs(SAMPLE_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of Workers for dataloader\nworkers = 2\n\n# Batch size for training\nbatch_size = 128\n\n# Image size\nimage_size = 64\n\n# Number of channels of image \nchannels = 3\n\n# Number of latent vectors i.e output of generator\nlatent_vectors = 100\n\n# Size of Feature map in generator\nngf = 64\n\n# Size of Feature map in Discriminator\nndf = 64\n\n# Number of Epochs\nnum_epochs = 5\n\n# Learning Rate \nlr = 0.0002\n\n# Beta1 HyperParamter for Adam Optimizer \nbeta1 = 0.5\n\n","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"e804f880d4ebb38d3738fed26aebce69eda657fd"},"cell_type":"markdown","source":"## 4. Load Data"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T06:02:50.200318Z","start_time":"2018-04-04T06:02:49.706612Z"},"trusted":true,"_uuid":"a37abdb26b2dee12502e9aaf0209cf82be09f6ba"},"cell_type":"code","source":"# Create the Dataset\ndataset = datasets.ImageFolder(IMAGE_PATH, \n                             transform=transforms.Compose([\n                                 transforms.Resize(image_size),\n                                 transforms.CenterCrop(image_size),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n                             ]))\n\n# Create the dataloader\ndataloader = tutils.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Visualize Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"real_data = next(iter(dataloader))\nplt.figure(figsize=(8,8))\nplt.title('Training Images')\nplt.imshow(np.transpose(vutils.make_grid(real_data[0].to(device)[:64], padding=2, normalize=True).cpu(), (1, 2, 0)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c00320fab9d2b12cf53f5af3a9bdec0cb518175"},"cell_type":"markdown","source":"## 6. Initializing Weights"},{"metadata":{"ExecuteTime":{"end_time":"2018-04-04T06:02:52.496616Z","start_time":"2018-04-04T06:02:50.926448Z"},"trusted":true,"_uuid":"6da5809574999fcc35d78f455947c82dcc62a09c"},"cell_type":"code","source":"def init_weights(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7. Defining Architecture"},{"metadata":{},"cell_type":"markdown","source":"### a) Generator"},{"metadata":{},"cell_type":"markdown","source":"#### 1) Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d(latent_vectors, ngf*8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf*8),\n            nn.ReLU(True),\n            # Size will be ( ngf*8 x 4 x 4 )\n            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf*4),\n            nn.ReLU(True),\n            # Size will be ( ngf*4 x 8 x 8 )\n            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf*2),\n            nn.ReLU(True),\n            # Size will be ( ngf*2 x 16 x 16 )\n            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            # size will be ( ngf x 32 x 32 )\n            nn.ConvTranspose2d(ngf, channels, 4, 2, 1, bias=False ),\n            nn.Tanh()\n            # Output will be ( channel x 64 x 64 )\n        )\n    \n    def forward(self, x):\n        return self.main(x)","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2) Initialization"},{"metadata":{"trusted":true},"cell_type":"code","source":"generator_model = Generator().to(device)\n\ngenerator_model.apply(init_weights)\n\nprint(generator_model)","execution_count":18,"outputs":[{"output_type":"stream","text":"Generator(\n  (main): Sequential(\n    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace)\n    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace)\n    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU(inplace)\n    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (11): ReLU(inplace)\n    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (13): Tanh()\n  )\n)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### b) Discriminator"},{"metadata":{},"cell_type":"markdown","source":"#### 1) Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Discriminator(nn.Module):\n    \n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.main = nn.Sequential(\n            # input ( channel x 64 x 64)\n            nn.Conv2d(channels, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # size ( channel*2, 32, 32)\n            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf*2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # size ( ndf*2 x 16 x 16 )\n            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf*4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # size ndf*4 x 8 x 8\n            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf*8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # size ndf*8, 4, 4\n            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, x):\n        return self.main(x)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator_model = Discriminator().to(device)\n\ndiscriminator_model.apply(init_weights)\nprint(discriminator_model)","execution_count":30,"outputs":[{"output_type":"stream","text":"Discriminator(\n  (main): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (1): LeakyReLU(negative_slope=0.2, inplace)\n    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): LeakyReLU(negative_slope=0.2, inplace)\n    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): LeakyReLU(negative_slope=0.2, inplace)\n    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): LeakyReLU(negative_slope=0.2, inplace)\n    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n    (12): Sigmoid()\n  )\n)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 8. Setting Up Loss functions and Optimizers"},{"metadata":{"trusted":true},"cell_type":"code","source":"    criterion = nn.BCELoss()\n    fixed_noise = torch.randn(64, latent_vectors, 1, 1, device=device)\n    labels = {'real' : 1, 'fake' : 0}\n    \n    optimizerG = optim.Adam(generator_model.parameters(), lr=lr, betas=(beta1, 0.999))\n    optimizerD = optim.Adam(discriminator_model.parameters(), lr=lr, betas=(beta1, 0.999))\n    ","execution_count":31,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'nz' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-277a65bc0526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfixed_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'real'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fake'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizerG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'nz' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":1}