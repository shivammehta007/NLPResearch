{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Variational Encoder",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivammehta007/NLPResearch/blob/master/Tutorials/Generative%20Models/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgFXyBYV_fQ8",
        "colab_type": "text"
      },
      "source": [
        "Writing A Variational Encoder in PyTorch\n",
        "First Lets Import all the libraries needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCes9olUqAB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npKjzI_U_Sha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Be36ahBdEm",
        "colab_type": "text"
      },
      "source": [
        "Loading the Data, Lets use our favourite dataset MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGSPu3yj_24H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_data = datasets.MNIST(root='.data/', train=True, download=True, transform=transformer)\n",
        "test_data = datasets.MNIST(root='.data/',train=False, download=True, transform=transformer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7oxrcFBCC0e",
        "colab_type": "text"
      },
      "source": [
        "Initializing Data Set Iterators for easy and batched access"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdX2pq8m_3UI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_iterator = DataLoader(test_data, batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQilDVmVCZfr",
        "colab_type": "text"
      },
      "source": [
        "Now Lets Define the HyperParameters of our VAE \n",
        "Since, VAE is nothing but a combination of Autoencoders, lets define how our architecture will look like\n",
        "\n",
        "* size of each input\n",
        "* hidden dimension\n",
        "* latent vector dimension\n",
        "* learning rate      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UML4-G9dCYWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = 28 * 28\n",
        "HIDDEN_DIM = 256\n",
        "LATENT_DIM = 20\n",
        "lr = 1e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fik7ixbEC87K",
        "colab_type": "text"
      },
      "source": [
        "In VAE we have one Encoder $ q_\\phi (z | x) $ , Lets first define that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT0tAcVGC6UO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    '''\n",
        "        This is the Encoder of VAE\n",
        "    '''\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.linear = nn.Linear(input_dim, hidden_dim)\n",
        "        self.mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.var = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        hidden = F.relu(self.linear(x))\n",
        "        mu_z = self.mu(hidden)\n",
        "        var_z = self.var(hidden)\n",
        "\n",
        "        return mu_z, var_z\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkWgoLamFEGT",
        "colab_type": "text"
      },
      "source": [
        "Now, Lets Code Decoder $ p_\\theta (x | z) $  which will take latent as input and give generated image as output "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91f-NqqTFBlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    '''\n",
        "        This is the Decoder part of VAE\n",
        "    '''\n",
        "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.linear = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden = F.relu(self.linear(x))\n",
        "        output = torch.sigmoid(self.out(hidden))\n",
        "    \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnre8DJNIkqw",
        "colab_type": "text"
      },
      "source": [
        "Now we have both our encoder and decoder, Lets write the final architecture of our VAE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQafQcZ0Ijb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, enc, dec):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = enc\n",
        "        self.decoder = dec\n",
        "    \n",
        "    def sampling(self, mu, var):\n",
        "        std = torch.exp(var / 2)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add_(mu)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "\n",
        "        mu_z, var_z = self.encoder(x)\n",
        "\n",
        "        x_sample = self.sampling(mu_z, var_z)\n",
        "    \n",
        "        prediction = self.decoder(x_sample)\n",
        "\n",
        "        return prediction, mu_z, var_z\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWoRBbI7JrLV",
        "colab_type": "text"
      },
      "source": [
        "Lets, Initialize the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MbIwR-wJdVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(INPUT_DIM, HIDDEN_DIM, LATENT_DIM)\n",
        "decoder = Decoder(LATENT_DIM, HIDDEN_DIM, INPUT_DIM)\n",
        "\n",
        "model = VAE(encoder, decoder).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBwj7K2QKJLc",
        "colab_type": "text"
      },
      "source": [
        "So we know that the LOSS of VAE is the Reconstruction loss and KL Divergence\n",
        "So final loss function will give be = RL + KL\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb0Sj0oCKCp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reconstruction_loss(sampled_input, original_input):\n",
        "    return F.binary_cross_entropy(sampled_input, original_input, size_average=False)\n",
        "\n",
        "def kl_divergence(mu_z, var_z):\n",
        "    return 0.5 * torch.sum(torch.exp(var_z) + mu_z**2 - 1.0 - var_z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1qqHBUqLETr",
        "colab_type": "text"
      },
      "source": [
        "Lets now Train the Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8v09-bFK65E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0\n",
        "\n",
        "    for i, (x, _) in enumerate(iterator):\n",
        "        # Update the size of array\n",
        "        x = x.view(-1, INPUT_DIM).to(device)\n",
        "\n",
        "        # Forward Prop\n",
        "        x_sample, mu_z, var_z = model(x)\n",
        "\n",
        "        # Calculating Loss\n",
        "        loss = reconstruction_loss(x_sample, x) + kl_divergence(mu_z, var_z)\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "\n",
        "        # Update Train_loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.step()\n",
        "    \n",
        "    return train_loss\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NtTH-pAMh94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, iterator, optimizer):\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (x, _) in enumerate(iterator):\n",
        "            x = x.view(-1, INPUT_DIM).to(device)\n",
        "\n",
        "            x_sample, mu_z, var_z = model(x)\n",
        "\n",
        "            loss = reconstruction_loss(x_sample, x) + kl_divergence(mu_z, var_z)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "    \n",
        "    return test_loss\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jCzWj1VNduI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_EPOCHS = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tdBnvU5NFue",
        "colab_type": "text"
      },
      "source": [
        "Finally Training the Model with iterators and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyIyJBc6NAvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "32bc7355-1b6b-4346-e0ce-1ff1b8d4e505"
      },
      "source": [
        " for epoch in range(N_EPOCHS):\n",
        "\n",
        "        train_loss = train(model, train_iterator, optimizer)\n",
        "        test_loss = test(model, test_iterator, optimizer)\n",
        "\n",
        "        train_loss /= len(train_data)\n",
        "        test_loss /= len(test_data)\n",
        "\n",
        "        print('Epoch :{}, Train_loss : {} Test_loss: {}'.format(epoch + 1, train_loss, test_loss))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch :1, Train_loss : 247.691322648112 Test_loss: 225.584222265625\n",
            "Epoch :2, Train_loss : 227.8959071126302 Test_loss: 230.0393634765625\n",
            "Epoch :3, Train_loss : 235.24255581054686 Test_loss: 242.44127458496095\n",
            "Epoch :4, Train_loss : 239.46109811197917 Test_loss: 238.11618540039063\n",
            "Epoch :5, Train_loss : 232.37769921061198 Test_loss: 227.071475390625\n",
            "Epoch :6, Train_loss : 224.911977734375 Test_loss: 224.69393198242187\n",
            "Epoch :7, Train_loss : 227.88393933105468 Test_loss: 230.19263952636717\n",
            "Epoch :8, Train_loss : 230.1887731282552 Test_loss: 230.05522958984375\n",
            "Epoch :9, Train_loss : 228.1150557779948 Test_loss: 226.16292204589843\n",
            "Epoch :10, Train_loss : 227.5982838297526 Test_loss: 228.75995822753907\n",
            "Epoch :11, Train_loss : 230.84038704427084 Test_loss: 233.88991337890624\n",
            "Epoch :12, Train_loss : 234.70716589355467 Test_loss: 234.54342807617186\n",
            "Epoch :13, Train_loss : 233.82448494466146 Test_loss: 231.7353688232422\n",
            "Epoch :14, Train_loss : 231.02353225097656 Test_loss: 231.79360141601563\n",
            "Epoch :15, Train_loss : 236.57211967773438 Test_loss: 244.07409685058593\n",
            "Epoch :16, Train_loss : 240.12448011067707 Test_loss: 235.4799810546875\n",
            "Epoch :17, Train_loss : 234.9132526204427 Test_loss: 234.27324177246095\n",
            "Epoch :18, Train_loss : 237.69882096354166 Test_loss: 242.8841795410156\n",
            "Epoch :19, Train_loss : 250.41395009765625 Test_loss: 252.30067392578124\n",
            "Epoch :20, Train_loss : 247.81758415527344 Test_loss: 242.09741994628905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUCuItrXNbGq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "695ba6ce-7e36-47ac-9fab-da234c493a48"
      },
      "source": [
        "z = torch.randn(1, LATENT_DIM).to(device)\n",
        "\n",
        "# run only the decoder\n",
        "reconstructed_img = model.decoder(z)\n",
        "img = reconstructed_img.view(28, 28).data\n",
        "\n",
        "print(z.shape)\n",
        "print(img.shape)\n",
        "plt.imshow(img.cpu(), cmap='gray')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 20])\n",
            "torch.Size([28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f360c445f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZfilpgy/1JThl5oy/FJThl9q6v8BZArFVsDp0H8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBnjlardPYVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}